{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#初识-NLTK\" data-toc-modified-id=\"初识-NLTK-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>初识 NLTK</a></div><div class=\"lev2 toc-item\"><a href=\"#库\" data-toc-modified-id=\"库-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>库</a></div><div class=\"lev2 toc-item\"><a href=\"#搜索文本\" data-toc-modified-id=\"搜索文本-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>搜索文本</a></div><div class=\"lev2 toc-item\"><a href=\"#近义词\" data-toc-modified-id=\"近义词-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>近义词</a></div><div class=\"lev2 toc-item\"><a href=\"#文本位置\" data-toc-modified-id=\"文本位置-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>文本位置</a></div><div class=\"lev2 toc-item\"><a href=\"#统计\" data-toc-modified-id=\"统计-15\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>统计</a></div><div class=\"lev1 toc-item\"><a href=\"#语料与词汇资源\" data-toc-modified-id=\"语料与词汇资源-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>语料与词汇资源</a></div><div class=\"lev2 toc-item\"><a href=\"#NLTK-语料库\" data-toc-modified-id=\"NLTK-语料库-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>NLTK 语料库</a></div><div class=\"lev3 toc-item\"><a href=\"#nltk.corpus.gutenberg-方法\" data-toc-modified-id=\"nltk.corpus.gutenberg-方法-211\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>nltk.corpus.gutenberg 方法</a></div><div class=\"lev3 toc-item\"><a href=\"#其他语料库\" data-toc-modified-id=\"其他语料库-212\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>其他语料库</a></div><div class=\"lev2 toc-item\"><a href=\"#语料库一般结构\" data-toc-modified-id=\"语料库一般结构-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>语料库一般结构</a></div><div class=\"lev2 toc-item\"><a href=\"#语料库通用接口\" data-toc-modified-id=\"语料库通用接口-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>语料库通用接口</a></div><div class=\"lev2 toc-item\"><a href=\"#加载自己的语料库\" data-toc-modified-id=\"加载自己的语料库-24\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>加载自己的语料库</a></div><div class=\"lev2 toc-item\"><a href=\"#条件频率分布\" data-toc-modified-id=\"条件频率分布-25\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>条件频率分布</a></div><div class=\"lev3 toc-item\"><a href=\"#输出布朗语料库中每个类别下每个词的频率\" data-toc-modified-id=\"输出布朗语料库中每个类别下每个词的频率-251\"><span class=\"toc-item-num\">2.5.1&nbsp;&nbsp;</span>输出布朗语料库中每个类别下每个词的频率</a></div><div class=\"lev3 toc-item\"><a href=\"#按最大条件概率生成双连词，并生成随机文本\" data-toc-modified-id=\"按最大条件概率生成双连词，并生成随机文本-252\"><span class=\"toc-item-num\">2.5.2&nbsp;&nbsp;</span>按最大条件概率生成双连词，并生成随机文本</a></div><div class=\"lev2 toc-item\"><a href=\"#其他词典资源\" data-toc-modified-id=\"其他词典资源-26\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>其他词典资源</a></div><div class=\"lev1 toc-item\"><a href=\"#词性标注\" data-toc-modified-id=\"词性标注-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>词性标注</a></div><div class=\"lev2 toc-item\"><a href=\"#英文词干提取\" data-toc-modified-id=\"英文词干提取-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>英文词干提取</a></div><div class=\"lev2 toc-item\"><a href=\"#词性标注器\" data-toc-modified-id=\"词性标注器-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>词性标注器</a></div><div class=\"lev3 toc-item\"><a href=\"#自己标注语料库\" data-toc-modified-id=\"自己标注语料库-321\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>自己标注语料库</a></div><div class=\"lev3 toc-item\"><a href=\"#中文也可以标注\" data-toc-modified-id=\"中文也可以标注-322\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>中文也可以标注</a></div><div class=\"lev3 toc-item\"><a href=\"#中文语料库\" data-toc-modified-id=\"中文语料库-323\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>中文语料库</a></div><div class=\"lev3 toc-item\"><a href=\"#中文分词：jieba\" data-toc-modified-id=\"中文分词：jieba-324\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>中文分词：jieba</a></div><div class=\"lev2 toc-item\"><a href=\"#词性自动标注\" data-toc-modified-id=\"词性自动标注-33\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>词性自动标注</a></div><div class=\"lev3 toc-item\"><a href=\"#DefaultTagger-默认标注器\" data-toc-modified-id=\"DefaultTagger-默认标注器-331\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>DefaultTagger 默认标注器</a></div><div class=\"lev3 toc-item\"><a href=\"#正则表达式标注器\" data-toc-modified-id=\"正则表达式标注器-332\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>正则表达式标注器</a></div><div class=\"lev3 toc-item\"><a href=\"#查询标注器\" data-toc-modified-id=\"查询标注器-333\"><span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span>查询标注器</a></div><div class=\"lev4 toc-item\"><a href=\"#一元标注\" data-toc-modified-id=\"一元标注-3331\"><span class=\"toc-item-num\">3.3.3.1&nbsp;&nbsp;</span>一元标注</a></div><div class=\"lev4 toc-item\"><a href=\"#多元标注\" data-toc-modified-id=\"多元标注-3332\"><span class=\"toc-item-num\">3.3.3.2&nbsp;&nbsp;</span>多元标注</a></div><div class=\"lev3 toc-item\"><a href=\"#组合标注器\" data-toc-modified-id=\"组合标注器-334\"><span class=\"toc-item-num\">3.3.4&nbsp;&nbsp;</span>组合标注器</a></div><div class=\"lev3 toc-item\"><a href=\"#标注器存储\" data-toc-modified-id=\"标注器存储-335\"><span class=\"toc-item-num\">3.3.5&nbsp;&nbsp;</span>标注器存储</a></div><div class=\"lev1 toc-item\"><a href=\"#文本分类\" data-toc-modified-id=\"文本分类-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>文本分类</a></div><div class=\"lev2 toc-item\"><a href=\"#nltk-中的贝叶斯\" data-toc-modified-id=\"nltk-中的贝叶斯-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>nltk 中的贝叶斯</a></div><div class=\"lev2 toc-item\"><a href=\"#文档分类\" data-toc-modified-id=\"文档分类-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>文档分类</a></div><div class=\"lev4 toc-item\"><a href=\"#特征提取\" data-toc-modified-id=\"特征提取-4201\"><span class=\"toc-item-num\">4.2.0.1&nbsp;&nbsp;</span>特征提取</a></div><div class=\"lev4 toc-item\"><a href=\"#训练\" data-toc-modified-id=\"训练-4202\"><span class=\"toc-item-num\">4.2.0.2&nbsp;&nbsp;</span>训练</a></div><div class=\"lev4 toc-item\"><a href=\"#预测新文档\" data-toc-modified-id=\"预测新文档-4203\"><span class=\"toc-item-num\">4.2.0.3&nbsp;&nbsp;</span>预测新文档</a></div><div class=\"lev4 toc-item\"><a href=\"#最优信息量特征\" data-toc-modified-id=\"最优信息量特征-4204\"><span class=\"toc-item-num\">4.2.0.4&nbsp;&nbsp;</span>最优信息量特征</a></div><div class=\"lev4 toc-item\"><a href=\"#书中的例子\" data-toc-modified-id=\"书中的例子-4205\"><span class=\"toc-item-num\">4.2.0.5&nbsp;&nbsp;</span>书中的例子</a></div><div class=\"lev2 toc-item\"><a href=\"#其他文本分类\" data-toc-modified-id=\"其他文本分类-43\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>其他文本分类</a></div><div class=\"lev1 toc-item\"><a href=\"#一句话提取十句话\" data-toc-modified-id=\"一句话提取十句话-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>一句话提取十句话</a></div><div class=\"lev2 toc-item\"><a href=\"#结构化\" data-toc-modified-id=\"结构化-51\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>结构化</a></div><div class=\"lev2 toc-item\"><a href=\"#分块\" data-toc-modified-id=\"分块-52\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>分块</a></div><div class=\"lev2 toc-item\"><a href=\"#如何标记存储\" data-toc-modified-id=\"如何标记存储-53\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>如何标记存储</a></div><div class=\"lev2 toc-item\"><a href=\"#关系抽取\" data-toc-modified-id=\"关系抽取-54\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>关系抽取</a></div><div class=\"lev2 toc-item\"><a href=\"#程序\" data-toc-modified-id=\"程序-55\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>程序</a></div><div class=\"lev1 toc-item\"><a href=\"#文法分析\" data-toc-modified-id=\"文法分析-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>文法分析</a></div><div class=\"lev2 toc-item\"><a href=\"#语法和文法\" data-toc-modified-id=\"语法和文法-61\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>语法和文法</a></div><div class=\"lev2 toc-item\"><a href=\"#文法特征结构\" data-toc-modified-id=\"文法特征结构-62\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>文法特征结构</a></div><div class=\"lev2 toc-item\"><a href=\"#特征结构处理\" data-toc-modified-id=\"特征结构处理-63\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>特征结构处理</a></div><div class=\"lev3 toc-item\"><a href=\"#查找国家城市的-sql-语句的文法\" data-toc-modified-id=\"查找国家城市的-sql-语句的文法-631\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;</span>查找国家城市的 sql 语句的文法</a></div><div class=\"lev1 toc-item\"><a href=\"#重温-NLP\" data-toc-modified-id=\"重温-NLP-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>重温 NLP</a></div><div class=\"lev2 toc-item\"><a href=\"#NLP-怎么学\" data-toc-modified-id=\"NLP-怎么学-71\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>NLP 怎么学</a></div><div class=\"lev2 toc-item\"><a href=\"#NLP-学什么\" data-toc-modified-id=\"NLP-学什么-72\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>NLP 学什么</a></div><div class=\"lev2 toc-item\"><a href=\"#NLP-应用\" data-toc-modified-id=\"NLP-应用-73\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>NLP 应用</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初识 NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搜索文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 20 of 20 matches:\n",
      "s of the sea , appeared . Among the former , one was of a most monstrous size \n",
      "ce , borrowed from the chaplain ' s former sea - farings . Between the marble \n",
      "s him with a fresh lance , when the former one has been badly twisted , or elb\n",
      " , though smaller than those of the former order , nevertheless retain a propo\n",
      "fficial is still retained , but his former dignity is sadly abridged . At pres\n",
      " tested reality of his might had in former legendary times thrown its shadow b\n",
      "g associated with the experience of former perils ; for what knows he , this N\n",
      "ns and places in which , on various former voyages of various ships , sperm wh\n",
      ". So that though Moby Dick had in a former year been seen , for example , on w\n",
      "ed by the defection of seven of his former associates , and stung by the mocki\n",
      "no part in the mutiny , he told the former that he had a good mind to flog the\n",
      " so for ever got the start of their former captain , had he been at all minded\n",
      " head is cut off whole , but in the former the lips and tongue are separately \n",
      "nd the right . While the ear of the former has an external opening , that of t\n",
      "in small detached companies , as in former times , are now frequently met with\n",
      "ence on the coast of Greenland , in former times , of a Dutch village called S\n",
      "x months before he wheeled out of a former equinox at Aries ! From storm to st\n",
      "Sperm Whale , for example , that in former years ( the latter part of the last\n",
      "les no longer haunt many grounds in former years abounding with them , hence t\n",
      "ering was but the direct issue of a former woe ; and he too plainly seemed to \n"
     ]
    }
   ],
   "source": [
    "## 搜索文本\n",
    "text1.concordance(\"former\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 近义词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whale boat sea captain world way head time crew man other pequod line\n",
      "deck body fishery air boats side voyage\n"
     ]
    }
   ],
   "source": [
    "# 近义词\n",
    "text1.similar(\"ship\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 出现的位置\n",
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260819"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 总字数\n",
    "len(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'.',\n",
       " u'1851',\n",
       " u'Dick',\n",
       " u'ETYMOLOGY',\n",
       " u'Herman',\n",
       " u'Melville',\n",
       " u'Moby',\n",
       " u'[',\n",
       " u']',\n",
       " u'by'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 所有词集合/不重复字\n",
    "set(text1[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19317"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 总词数\n",
    "len(set(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回 某个词 出现的总词数\n",
    "text5.count(\"lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 统计文章词频，并按从大到小排序存到一个列表\n",
    "feq = FreqDist(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.probability.FreqDist"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({u')': 1,\n",
       "          u',': 3,\n",
       "          u'--': 1,\n",
       "          u';': 1,\n",
       "          u'I': 1,\n",
       "          u'School': 1,\n",
       "          u'The': 1,\n",
       "          u'Usher': 1,\n",
       "          u'and': 1,\n",
       "          u'body': 1,\n",
       "          u'brain': 1,\n",
       "          u'coat': 1,\n",
       "          u'heart': 1,\n",
       "          u'him': 1,\n",
       "          u'in': 1,\n",
       "          u'pale': 1,\n",
       "          u'see': 1,\n",
       "          u'threadbare': 1})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FreqDist(text1[20:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 统计词频，并输出累计图像\n",
    "fdist1 = FreqDist(text1);\n",
    "fdist1.plot(50,cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'funereal',\n",
       " u'unscientific',\n",
       " u'prefix',\n",
       " u'plaudits',\n",
       " u'woody',\n",
       " u'disobeying',\n",
       " u'Westers',\n",
       " u'DRYDEN',\n",
       " u'Untried',\n",
       " u'superficially']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回只出现一次的词\n",
    "fdist1.hapaxes()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9002"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdist1.hapaxes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; four years; years ago; Federal\n",
      "Government; General Government; American people; Vice President; Old\n",
      "World; Almighty God; Fellow citizens; Chief Magistrate; Chief Justice;\n",
      "God bless; every citizen; Indian tribes; public debt; one another;\n",
      "foreign nations; political parties\n"
     ]
    }
   ],
   "source": [
    "# 频繁的双联词\n",
    "text4.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 每个单词长度出现的频率\n",
    "fdist = FreqDist([len(w) for w in text1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({1: 47933,\n",
       "          2: 38513,\n",
       "          3: 50223,\n",
       "          4: 42345,\n",
       "          5: 26597,\n",
       "          6: 17111,\n",
       "          7: 14399,\n",
       "          8: 9966,\n",
       "          9: 6428,\n",
       "          10: 3528,\n",
       "          11: 1873,\n",
       "          12: 1053,\n",
       "          13: 567,\n",
       "          14: 177,\n",
       "          15: 70,\n",
       "          16: 22,\n",
       "          17: 12,\n",
       "          18: 1,\n",
       "          20: 1})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 长度为 3 的最多\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50223"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19255882431878046"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 长度为 3 的单词占了全书所有词汇的 20%\n",
    "fdist.freq(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 语料与词汇资源"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK 语料库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'austen-emma.txt',\n",
       " u'austen-persuasion.txt',\n",
       " u'austen-sense.txt',\n",
       " u'bible-kjv.txt',\n",
       " u'blake-poems.txt',\n",
       " u'bryant-stories.txt',\n",
       " u'burgess-busterbrown.txt',\n",
       " u'carroll-alice.txt',\n",
       " u'chesterton-ball.txt',\n",
       " u'chesterton-brown.txt',\n",
       " u'chesterton-thursday.txt',\n",
       " u'edgeworth-parents.txt',\n",
       " u'melville-moby_dick.txt',\n",
       " u'milton-paradise.txt',\n",
       " u'shakespeare-caesar.txt',\n",
       " u'shakespeare-hamlet.txt',\n",
       " u'shakespeare-macbeth.txt',\n",
       " u'whitman-leaves.txt']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gutenberg 语料库的文件标识符\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.corpus.gutenberg 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'[The Wisdom of Fathe'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输出 文章 的原始内容\n",
    "nltk.corpus.gutenberg.raw('chesterton-brown.txt')[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406629"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'[', u'The', u'Wisdom', u'of', u'Father', u'Brown', ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输出 文章 的单词列表\n",
    "nltk.corpus.gutenberg.words('chesterton-brown.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86063"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 输出 文章 的句子列表\n",
    "sents = nltk.corpus.gutenberg.sents('chesterton-brown.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3806"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 其他语料库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 网络文本语料库，网络和聊天文本\n",
    "from nltk.corpus import webtext\n",
    "# 布朗语料库，按照文本分类好的 500 个不同来源的文本\n",
    "from nltk.corpus import brown\n",
    "# 路途社语料库，1 万多个新闻文档\n",
    "from nltk.corpus import reuters\n",
    "# 就职演说语料库，55 个总统的演说\n",
    "from nltk.corpus import inaugural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 语料库一般结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 散养式：孤立的多篇文章\n",
    "- 分类式：按照类别组织，相互之间没有交集\n",
    "- 交叉式：一篇文章可能属于多个类\n",
    "- 渐变式：语法随着时间发生变化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 语料库通用接口"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `fileids()` 返回语料库中的文件\n",
    "- `categories()` 返回语料库中的分类\n",
    "- `raw()` 返回语料库的原始内容\n",
    "- `words()` 返回语料库中的词汇\n",
    "- `sents()` 返回语料库中的句子\n",
    "- `abspath()` 指定文件在磁盘上的位置\n",
    "- `open()` 打开语料库的文件流"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'firefox.txt',\n",
       " u'grail.txt',\n",
       " u'overheard.txt',\n",
       " u'pirates.txt',\n",
       " u'singles.txt',\n",
       " u'wine.txt']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webtext.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'adventure',\n",
       " u'belles_lettres',\n",
       " u'editorial',\n",
       " u'fiction',\n",
       " u'government',\n",
       " u'hobbies',\n",
       " u'humor',\n",
       " u'learned',\n",
       " u'lore',\n",
       " u'mystery',\n",
       " u'news',\n",
       " u'religion',\n",
       " u'reviews',\n",
       " u'romance',\n",
       " u'science_fiction']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载自己的语料库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_root = './tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordlists = PlaintextCorpusReader(corpus_root, '.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['README.md', 'happiness_seg.txt', 'learntf.py']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlists.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 条件频率分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出布朗语料库中每个类别下每个词的频率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "# 链表推导式，genre 是所有类别列表，word 是这个类别中的词汇列表\n",
    "# (genre, word) 就是类别加词汇对\n",
    "genre_word = [(genre, word)\n",
    "             for genre in brown.categories()\n",
    "             for word in brown.words(categories=genre)]\n",
    "\n",
    "# 创建条件频率分布\n",
    "cfd = nltk.ConditionalFreqDist(genre_word)\n",
    "\n",
    "# 指定条件和样本作图/不同类别，每个 sample 出现的频率\n",
    "cfd.plot(conditions=['news', 'adventure'], samples=[u'stock', u'sunbonnet', u'Elevated', u'narcotic', u'four', \\\n",
    "                                                    u'woods', u'railing', u'Until', u'aggression', u'marching', \\\n",
    "                                                    u'looking', u'eligible', u'electricity', u'$25-a-plate', \\\n",
    "                                                    u'consulate', u'Casey', u'all-county', u'Belgians', \\\n",
    "                                                    u'Western', u'1959-60', u'Duhagon', u'sinking', u'1,119', \\\n",
    "                                                    u'co-operation', u'Famed', u'regional', u'Charitable', \\\n",
    "                                                    u'appropriation', u'yellow', u'uncertain', u'Heights', \\\n",
    "                                                    u'bringing', u'prize', u'Loen', u'Publique', u'wooden', \\\n",
    "                                                    u'Loeb', u'963', u'specialties', u'Sands', u'succession', \\\n",
    "                                                    u'Paul', u'Phyfe'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot 改成 tabulate，就可以输出表格格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'adventure',\n",
       " u'belles_lettres',\n",
       " u'editorial',\n",
       " u'fiction',\n",
       " u'government',\n",
       " u'hobbies',\n",
       " u'humor',\n",
       " u'learned',\n",
       " u'lore',\n",
       " u'mystery',\n",
       " u'news',\n",
       " u'religion',\n",
       " u'reviews',\n",
       " u'romance',\n",
       " u'science_fiction']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words(categories='news').count('four')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 按最大条件概率生成双连词，并生成随机文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding(\"utf-8\")\n",
    "\n",
    "import nltk\n",
    "\n",
    "# 循环 10 次，从 cfdist 中取出当前单词最大概率的连词，并打印\n",
    "def generate_model(cfdist, word, num=10):\n",
    "    for i in range(num):\n",
    "        print word,\n",
    "        word = cfdist[word].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 加载语料库\n",
    "text = nltk.corpus.genesis.words('english-kjv.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 生成双连词\n",
    "bigrams = nltk.bigrams(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 生成条件频率分布\n",
    "cfd = nltk.ConditionalFreqDist(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 以 the 开头，生成随机串\n",
    "generate_model(cfd, 'the')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他词典资源"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 词汇列表语料库：`nltk.corpus.words.words()`；所有英文单词，可以用来识别语法错误\n",
    "- 停用词语料库：`nltk.corpus.stopwords.words`；识别最频繁出现的没有意义的词\n",
    "- 发音词典：`nltk.corpus.cmudict.dict()`；输出每个英文单词的发音\n",
    "- 比较词表：`nltk.corpus.swadesh`；多种语言核心 200 多个词的对照，可以作为语言翻译的基础\n",
    "- 同义词表：`WordNet'`；面向语义的英语词典，由同义词集组成，并组成一个网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 词性标注"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 英文词干提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "porter = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'lie'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem('lying')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词性标注器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "text = nltk.word_tokenize(\"And now for something completely different\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自己标注语料库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_token = nltk.tag.str2tuple('fle/NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fle', 'NN')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 中文也可以标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = '我/NN 是/IN 一个/AT 大JJ 傻x/NN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\xe6\\x88\\x91', 'NN'),\n",
       " ('\\xe6\\x98\\xaf', 'IN'),\n",
       " ('\\xe4\\xb8\\x80\\xe4\\xb8\\xaa', 'AT'),\n",
       " ('\\xe5\\xa4\\xa7JJ', None),\n",
       " ('\\xe5\\x82\\xbbx', 'NN')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[nltk.tag.str2tuple(t) for t in sent.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 中文语料库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in nltk.corpus.sinica_treebank.tagged_words():\n",
    "    print word[0], word[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 中文分词：jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词性自动标注"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DefaultTagger 默认标注器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不知道什么词，标记为中文语料概率最大的名词（13%）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "\n",
    "raw = \"我 累 个 去\"\n",
    "tokens = nltk.word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\xe6\\x88\\x91', '\\xe7\\xb4\\xaf', '\\xe4\\xb8\\xaa', '\\xe5\\x8e\\xbb']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = default_tagger.tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正则表达式标注器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "满足特定正则的被认为是某种词性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern = [(r'.*们$', 'PRO')] # 以们结尾的被认为是代词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger = nltk.RegexpTagger(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\xe6\\x88\\x91\\xe4\\xbb\\xac', 'PRO'),\n",
       " ('\\xe7\\xb4\\xaf', None),\n",
       " ('\\xe4\\xb8\\xaa', None),\n",
       " ('\\xe5\\x8e\\xbb', None),\n",
       " ('\\xe4\\xbd\\xa0\\xe4\\xbb\\xac', 'PRO'),\n",
       " ('\\xe5\\x92\\x8c', None),\n",
       " ('\\xe4\\xbb\\x96\\xe4\\xbb\\xac', 'PRO'),\n",
       " ('\\xe5\\x95\\x8a', None)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(nltk.word_tokenize('我们 累 个 去 你们 和 他们 啊'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查询标注器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找出最频繁的 n 个词以及它的词性，然后用这个信息去查找语料库，匹配的就标记上，剩余的词使用默认标注器（回退），一般使用一元标注方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一元标注"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于已经标注的语料库做训练，然后用训练好的模型来标注新的语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_sents = [[( u'我', u'PRO'), (u'小兔', u'NN')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigram_tagger = nltk.UnigramTagger(tagged_sents) # 标注器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents = [[u'我', u'你', u'小兔']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = unigram_tagger.tag(sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'\\u6211', u'PRO'), (u'\\u4f60', None), (u'\\u5c0f\\u5154', u'NN')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 布朗语料库，按照文本分类好的 500 个不同来源的文本\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sents = brown.sents(categories='news')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tagged_sents 是用于训练的语料库，可以直接用已经标记好的语料库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brown_tagged_sents = brown.tagged_sents(categories='news')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多元标注"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一元标注不考虑上下文，二元标注考虑它前面的词  \n",
    "\n",
    "- 二元标注：BigramTagger\n",
    "- 三元标注：TrigramTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 组合标注器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 二元标注器，一元标注器，默认标注器\n",
    "t0 = nltk.DefaultTagger('NN')\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff=t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = nltk.DefaultTagger('NN')\n",
    "t1 = nltk.UnigramTagger(brown.tagged_sents(categories='news'), backoff=t0)\n",
    "t2 = nltk.BigramTagger(brown.tagged_sents(categories='news'), backoff=t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DefaultTagger: tag=NN>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<UnigramTagger: size=11584>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BigramTagger: size=3462>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标注器存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cPickle import dump\n",
    "output = open('t2.pkl', 'wb')\n",
    "dump(t2, output, -1)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nltk 中的贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_train_set = [\n",
    "        ({'feature1':u'a'},'1'),\n",
    "        ({'feature1':u'a'},'2'),\n",
    "        ({'feature1':u'a'},'3'),\n",
    "        ({'feature1':u'a'},'3'),\n",
    "        ({'feature1':u'b'},'2'),\n",
    "        ({'feature1':u'b'},'2'),\n",
    "        ({'feature1':u'b'},'2'),\n",
    "        ({'feature1':u'b'},'2'),\n",
    "        ({'feature1':u'b'},'2'),\n",
    "        ({'feature1':u'b'},'2'),\n",
    "        ]\n",
    "classifier = nltk.NaiveBayesClassifier.train(my_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3', '2')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify({'feature1':u'a'}),classifier.classify({'feature1':u'b'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文档分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不管是什么分类，最重要的是要知道哪些特征是最能反映这个分类的特点，也就是特征选取。文档分类使用的特征就是最能代表这个分类的词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 因为对文档分类要经过训练和预测两个过程，而特征的提取是这两个过程都需要的，所以，习惯上我们会把特征提取单独抽象出来作为一个公共方法，比如："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_reviews.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39768"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'sucess',\n",
       " u'sonja',\n",
       " u'askew',\n",
       " u'woods',\n",
       " u'spiders',\n",
       " u'bazooms',\n",
       " u'hanging',\n",
       " u'francesca',\n",
       " u'comically',\n",
       " u'localized']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words.keys()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_features = all_words.keys()[:2000] # 已按顺序排好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words) # 返回 0 1 value\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# documents 应该是包含文本和标签的集合，返回的是 每个 word 是否在 word_features, 以及对应的标签\n",
    "featuresets = [(document_features(d), c) for (d, c) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(featuresets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预测新文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.classify(document_features(d)) # 对所有自变量求 “是否包含 2000 个词” 来判断该文本的标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最优信息量特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 书中的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "        [(name, 'female') for name in names.words('female.txt')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Aamir', 'male'),\n",
       " (u'Aaron', 'male'),\n",
       " (u'Abbey', 'male'),\n",
       " (u'Abbie', 'male'),\n",
       " (u'Abbot', 'male'),\n",
       " (u'Abbott', 'male'),\n",
       " (u'Abby', 'male'),\n",
       " (u'Abdel', 'male'),\n",
       " (u'Abdul', 'male'),\n",
       " (u'Abdulkarim', 'male')]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Coralyn', 'female'),\n",
       " (u'Huntlee', 'male'),\n",
       " (u'Bryant', 'male'),\n",
       " (u'Marjory', 'female'),\n",
       " (u'Abagael', 'female'),\n",
       " (u'Gui', 'female'),\n",
       " (u'Alphonso', 'male'),\n",
       " (u'Cameo', 'female'),\n",
       " (u'Gavrielle', 'female'),\n",
       " (u'Binnie', 'female')]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresets = [(gender_features(n), g) for (n,g) in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'last_letter': u'n'}, 'female'),\n",
       " ({'last_letter': u'e'}, 'male'),\n",
       " ({'last_letter': u't'}, 'male'),\n",
       " ({'last_letter': u'y'}, 'female'),\n",
       " ({'last_letter': u'l'}, 'female'),\n",
       " ({'last_letter': u'i'}, 'female'),\n",
       " ({'last_letter': u'o'}, 'male'),\n",
       " ({'last_letter': u'o'}, 'female'),\n",
       " ({'last_letter': u'e'}, 'female'),\n",
       " ({'last_letter': u'e'}, 'female')]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[500:], featuresets[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Neo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.736"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Informative Features\n",
    "             last_letter = u'k'             male : female =     42.7 : 1.0\n",
    "             last_letter = u'a'           female : male   =     36.3 : 1.0\n",
    "             last_letter = u'p'             male : female =     20.7 : 1.0\n",
    "             last_letter = u'f'             male : female =     15.8 : 1.0\n",
    "             last_letter = u'v'             male : female =     10.4 : 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他文本分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 词性标注：属于一种文本分类，一般是基于上下文语境的文本分类\n",
    "\n",
    "- 句子分割：属于标点符号的分类任务，它的特征一般选取为单独句子标识符的合并链表、数据特征（下一个词是否大写、前一个词是什么、前一个词长度……）\n",
    "\n",
    "- 识别对话行为类型：对话行为类型是指问候、问题、回答、断言、说明等\n",
    "\n",
    "- 识别文字蕴含：即一个句子是否能得出另外一个句子的结论，这可以认为是真假标签的分类任务。这是一个有挑战的事情"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一句话提取十句话"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结构化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了断句、分词、词性标注外，还有个关键：分块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 分块就是根据句子中的词和词性，按照某种规则组合在一起形成一个个分块，每个分块代表一个实体。常见的实体包括：组织、人员、地点、日期、时间等\n",
    "\n",
    "- 以上面的例子为例，首先我们做名词短语分块（NP-chunking），比如：技术问题。名词短语分块通过词性标记和一些规则就可以识别出来，也可以通过机器学习的方法识别\n",
    "\n",
    "- 除了名词短语分块还有很多其他分块：介词短语（PP，比如：以我……）、动词短语（VP，比如：打人）、句子（S，我是人）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何标记存储"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可以采用IOB标记，I(inside，内部)、O(outside，外部)、B(begin, 开始)，一个块的开始标记为B，块内的标识符序列标注为I，所有其他标识符标注为O\n",
    "\n",
    "- 也可以用树结构来存储分块，用树结构可以解决IOB无法标注的另一类分块，那就是多级分块。多级分块就是一句话可以有多重分块方法，比如：我以我的最高权利惩罚你。这里面“最高权利”、“我的最高权利”、“以我的最高权利”是不同类型分块形成一种多级分块，这是无法通过IOB标记的，但是用树结构可以。这也叫做级联分块。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关系抽取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通过上面的分块可以很容易识别出实体，那么关系抽取实际就是找出实体和实体之间的关系，这是自然语言处理一个质的跨越，实体识别让机器认知了一种事物，关系识别让机器掌握了一个真相。\n",
    "\n",
    "- 关系抽取的第一个方法就是找到(X, a, Y)这种三元组，其中 X 和 Y 都是实体，a 是表达关系的字符串，这完全可以通过正则来识别，因为不同语言有这不同的语法规则，所以方法都是不同的，比如中文里的“爱”可以作为这里的 a，但是“和”、“因为”等就不能作为这里的 a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import conll2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.txt', 'test.txt']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2000.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211727"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conll2000.words/raw('train.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259104"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conll2000.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Tree('S', [Tree('PP', [(u'Over', u'IN')]), Tree('NP', [(u'a', u'DT'), (u'cup', u'NN')]), Tree('PP', [(u'of', u'IN')]), Tree('NP', [(u'coffee', u'NN')]), (u',', u','), Tree('NP', [(u'Mr.', u'NNP'), (u'Stone', u'NNP')]), Tree('VP', [(u'told', u'VBD')]), Tree('NP', [(u'his', u'PRP$'), (u'story', u'NN')]), (u'.', u'.')])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2000.chunked_sents('train.txt')[99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文法分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 语法和文法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 这里面的 N 表示名词，Det 表示限定词，NP 表示名词短语，V 表示动词，VP 表示动词短语，S 表示句子。这种句子分析方法叫做语法分析\n",
    "\n",
    "- 因为句子可以无限组合无限扩展，所以单纯用语法分析来完成自然语言处理这件事情是不可能的，所以出现了文法分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 文法是一个潜在的无限的句子集合的一个紧凑的特性，它是通过一组形式化模型来表示的，文法可以覆盖所有结构的句子，对一个句子做文法分析，就是把句子往文法模型上靠，如果同时符合多种文法，那就是有歧义的句子\n",
    "\n",
    "- 最重要的结论：文法结构范围相当广泛，无法用规则类的方法来处理，只有利用基于特征的方法才能处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文法特征结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 文法特征举例：单词最后一个字母、词性标签、文法类别、正字拼写、指示物、关系、施事角色、受事角色\n",
    "\n",
    "- 因为文法特征是一种kv，所以特征结构的存储形式是字典\n",
    "\n",
    "- 不是什么样的句子都能提取出每一个文法特征的，需要满足一定的条件，这需要通过一系列的检查手段来达到，包括：句法协议（比如this dog就是对的，而these dog就是错的）、属性和约束、术语"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征结构处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs1 = nltk.FeatStruct(TENSE='past', NUM='sg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NUM='sg', TENSE='past']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs2 = nltk.FeatStruct(POS='N', AGR=fs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AGR=[NUM='sg', TENSE='past'], POS='N']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nltk 库里的产生式文法描述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls ~/nltk_data/grammars/book_grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查找国家城市的 sql 语句的文法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat ~/nltk_data/grammars/book_grammars/sql0.fcfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% start S\n",
    "\n",
    "S[SEM=(?np + WHERE + ?vp)] -> NP[SEM=?np] VP[SEM=?vp]\n",
    "\n",
    "VP[SEM=(?v + ?pp)] -> IV[SEM=?v] PP[SEM=?pp]\n",
    "VP[SEM=(?v + ?ap)] -> IV[SEM=?v] AP[SEM=?ap]\n",
    "NP[SEM=(?det + ?n)] -> Det[SEM=?det] N[SEM=?n]\n",
    "PP[SEM=(?p + ?np)] -> P[SEM=?p] NP[SEM=?np]\n",
    "AP[SEM=?pp] -> A[SEM=?a] PP[SEM=?pp]\n",
    "\n",
    "NP[SEM='Country=\"greece\"'] -> 'Greece'\n",
    "NP[SEM='Country=\"china\"'] -> 'China'\n",
    "\n",
    "Det[SEM='SELECT'] -> 'Which' | 'What'\n",
    "\n",
    "N[SEM='City FROM city_table'] -> 'cities'\n",
    "\n",
    "IV[SEM=''] -> 'are'\n",
    "A[SEM=''] -> 'located'\n",
    "P[SEM=''] -> 'in'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/evil_rabbit/chatRobot'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd ~/nltk_data/grammars/book_grammars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import load_parser\n",
    "cp = load_parser('sql0.fcfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = 'What cities are located in China'\n",
    "tokens = query.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', 'cities', 'are', 'located', 'in', 'China']"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tree in cp.parse(tokens):\n",
    "    print tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(S[SEM=(SELECT, City FROM city_table, WHERE, , , Country=\"china\")]\n",
    "  (NP[SEM=(SELECT, City FROM city_table)]\n",
    "    (Det[SEM='SELECT'] What)\n",
    "    (N[SEM='City FROM city_table'] cities))\n",
    "  (VP[SEM=(, , Country=\"china\")]\n",
    "    (IV[SEM=''] are)\n",
    "    (AP[SEM=(, Country=\"china\")]\n",
    "      (A[SEM=''] located)\n",
    "      (PP[SEM=(, Country=\"china\")]\n",
    "        (P[SEM=''] in)\n",
    "        (NP[SEM='Country=\"china\"'] China)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重温 NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP 怎么学"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 计算机领域的知识得倒着学，不管三七二十一先用起来，然后再系统地学习\n",
    "- nltk是最经典的自然语言处理的python库，不知道怎么用的看前几篇文章吧，先把它用起来，最起码做出来一个词性标注的小工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP 学什么"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 语言学：语言描述 语言理论 不同语言对比 语言共同点 语言发展的历史 语言的结构\n",
    "\n",
    "- 语音学：声音是怎么发出来的 声音是怎么传递的 声音是怎么接收的 \n",
    "\n",
    "- 概率论：贝叶斯 马尔科夫\n",
    "\n",
    "- 信息论：香农\n",
    "\n",
    "- 机器学习\n",
    "\n",
    "- 形式语言与自动机：形式语言包括：短语结构语言、上下文有关语言、上下文无关语言、正则语言等；自动机包括：图灵机、有穷自动机、下推自动机、线性有界自动机\n",
    "\n",
    "- 语言知识库\n",
    "\n",
    "- 语言模型\n",
    "\n",
    "- 分词、实体识别、词性标注：分词就是让计算机自动区分出汉字组成的词语；实体识别就是再分词之后能够根据各种短语形式判断出哪个词表示的是一个物体或组织或人名或……；词性标注就是给你一句话，你能识别出“名动形、数量代、副介连助叹拟声”\n",
    "\n",
    "- 句法分析：句法分析类似于小学时学的主谓宾补定状的区分，只是要在这基础上组合成短语，也就是把一个非结构化的句子分析称结构化的数据结构\n",
    "\n",
    "- 语义分析：看起来一步一步越来越深入了。语义是基于句法分析，进一步理解句子的意思，最重要的就是消除歧义，人姑且还会理解出歧义来呢，何况一个机器\n",
    "\n",
    "- 篇章分析。一堆堆的句子，每个都分析明白了，但是一堆句子组合成的篇章又怎么才能联系起来呢？你得总结出本文的中心思想不是？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP 应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 机器翻译\n",
    "- 语音翻译\n",
    "- 文本分类与情感分析\n",
    "- 信息检索与问答系统\n",
    "- 自动文摘和信息抽取\n",
    "- 人机对话。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "0px",
    "width": "0px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
